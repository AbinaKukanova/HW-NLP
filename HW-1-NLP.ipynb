{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание: Оценка тональности по словарю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках этого задания мы будем создавать программу, которая получая на вход отзыв, будет предсказывать, является отзыв положительным или отрицательным. Делать мы будем это таким образом: мы возьмём некоторое число отзывов, заранее размеченных как положительные или отрицательные; выделим те слова, которые встречаются только в положительных или только в отрицательных отзывах, и будем считать, каких слов в поступившем нам на проверку отзыве больше.\n",
    "\n",
    "Мы будем работать по заранее определённому пайплайну:\n",
    "\n",
    "Сначала нам надо скачать данные -- соберите как минимум 60 (30 положительных и 30 отрицательных) отзывов на похожие продукты (не надо мешать отзывы на отели с отзывами на ноутбуки) для составления \"тонального словаря\" (чем больше отзывов, тем лучше) и 10 отзывов для проверки качества. (2 балла в случае сбора путём парсинга, 1 - если найдете уже готовые данные или просто закопипастите без парсинга)\n",
    "Примечание: сбор данных с помощью краулинга может занять много времени, советуем сначала реализовать всё задание на готовых данных, а затем сделать с краулингом, если хотите получить 9 или 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import time\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy import array\n",
    "from pandas.core.common import flatten\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_main = r\"C:\\Users\\Abina Kukanova\\PycharmProjects\\homework\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим готовый датасет\n",
    "\n",
    "Подберем русскоязычный датасет с размеченной тональностью, используем корпус Linis Crowd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_texts_1 = pd.read_excel(\n",
    "    path_main + '\\\\linis_crowd_dataset\\\\doc_comment_summary.xlsx',\n",
    "    sheet_name = 0,\n",
    "    header=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Но при мужчине ни одна приличная женщина не по...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Украина это часть Руси искусственно отделенная...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как можно говорить об относительно небольшой к...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2014.  а что они со своими поляками сделали?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>у а фильмы... Зрители любят диковинное.   у ме...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26868</th>\n",
       "      <td>Многих заставляют. Многие сами проявляют излиш...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26869</th>\n",
       "      <td>Очередной Чубайс.  ну а чего нового то? Сорос ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26870</th>\n",
       "      <td>Закон, как все предыдущие - абсолютный бред и ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26871</th>\n",
       "      <td>дело которое ты делаешь сейчас - оно очень хор...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26872</th>\n",
       "      <td>Рядом с Токио, да, мало пальм :) Зато на Окина...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0   1\n",
       "0      Но при мужчине ни одна приличная женщина не по...  -1\n",
       "1      Украина это часть Руси искусственно отделенная...  -1\n",
       "2      Как можно говорить об относительно небольшой к...  -1\n",
       "3      1.2014.  а что они со своими поляками сделали?...   0\n",
       "4      у а фильмы... Зрители любят диковинное.   у ме...   0\n",
       "...                                                  ...  ..\n",
       "26868  Многих заставляют. Многие сами проявляют излиш...  -1\n",
       "26869  Очередной Чубайс.  ну а чего нового то? Сорос ...  -1\n",
       "26870  Закон, как все предыдущие - абсолютный бред и ...   0\n",
       "26871  дело которое ты делаешь сейчас - оно очень хор...   0\n",
       "26872  Рядом с Токио, да, мало пальм :) Зато на Окина...   0\n",
       "\n",
       "[26873 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_texts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_texts_1['label'] = pd.to_numeric(labeled_texts_1.iloc[:, 1], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_texts_1 = labeled_texts_1[[0, 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 0.0        13930\n",
       "-1.0         9203\n",
       " 1.0         1795\n",
       "-2.0         1534\n",
       " 2.0          365\n",
       " 22158.0        2\n",
       " 21887.0        1\n",
       " 23486.0        1\n",
       " 23523.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_texts_1.columns = ['text', 'label']\n",
    "labeled_texts_1.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([10224, 15325, 15786, 17474, 26375], dtype='int64')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_drop = labeled_texts_1.query('label > 2 or label < - 2').index\n",
    "\n",
    "ind_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_texts_1 = labeled_texts_1.query('index not in @ind_drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0.0\n",
      "Будте лояльнее, вам не идут инквизиторские замашки. Я вот жалею что рожала в роддоме и первого и полгода назад второго ребёнка. Я Вас очень прошу: Вы должны досконально изучать материал прежде чем сво\n",
      "\n",
      "label:  0.0\n",
      "..Всё самое страшное уже было без России и ничего не только справились , так ещё и поняли что можем и дальше справляться ..  А я знаю человека, котрый считает, что русские в центре России и русские в \n",
      "\n",
      "label:  0.0\n",
      "Но на краю пропасти есть шанс достучаться до здравого смысла в русском человеке - указав ему на пропасть под ногами и заставив вспомнить о предыдущем падении в эту пропасть. В экстремальных ситуациях \n",
      "\n",
      "label:  -2.0\n",
      "сли никогда не штрафуют то хоть 100500.  А они на красный начинают движение? Просто, если на зеленый и потом загорается красный - нужно пропускать, вроде.   Евгений, а почему Вы предлагаете увеличиват\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "\n",
    "    sample = labeled_texts_1.sample(n = 1)\n",
    "\n",
    "    print('label: ', sample.label.values[0])\n",
    "\n",
    "    print(sample['text'].values[0][:200])\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = labeled_texts_1.query('label != 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1.0    9203\n",
       " 1.0    1795\n",
       "-2.0    1534\n",
       " 2.0     365\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abina Kukanova\\AppData\\Local\\Temp\\ipykernel_34376\\2569160575.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected.loc[:, 'label_binary'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "selected.loc[:, 'label_binary'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.loc[((selected['label'] == -1) |\n",
    "         (selected['label'] == -2)), 'label_binary'] = 0\n",
    "\n",
    "selected.loc[((selected['label'] == 1) |\n",
    "         (selected['label'] == 2)), 'label_binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_binary\n",
       "0.0    10737\n",
       "1.0     2160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected.label_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  1.0\n",
      "Ответственность за последствия несет тот, кто кинул шланг под ноги прохожим, не оградил законным образом подотчетное имущество, и не предусмотрел его случайное повреждение.В любом случае, если некто в\n",
      "label:  0.0\n",
      "я, правда, с собаками когда иду, стараюсь им на глаза не попадаться, они на собак странно смотрят.  это просто праздник какой-то!  Американцы, японцы и корейцы, убейте северян, чтобы они не мучались! \n",
      "\n",
      "label:  1.0\n",
      "отому что самое страшное уже произошло - некоторые Мы родились в материальном мире, которому свойственны ограничения - как то: дорожные знаки, непроходимые насквозь скалы,  репейники, белые линии на д\n",
      "label:  0.0\n",
      "от и стараются, как могут!   Избавиться от предпринимателей мечтает не только власть, но и многие оборванцы из числа пролетарствующих маргиналов, которые шипят мне вслед, что я капиталист, буржуй и сп\n",
      "\n",
      "label:  1.0\n",
      "ознавательно. Что касается Цзян Цинь - то она оказалась хитрее и понятливее своей предшественницы, и по свидетельству Владимирова, сам подводила к Мао красивых танцовщиц на тусовках.  33а. Прямо как к\n",
      "label:  0.0\n",
      "Иначе ничего хорошего не получится.Это значит необходимо убрать для большинства преступлений  срок давности .Что бы гнида,жила бы всю жизнь с ощущением неминуемо надвигающегося возмездия.В любом возра\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "\n",
    "    sample_neg = selected.query('label_binary == 0').sample(n = 1)\n",
    "\n",
    "    sample_pos = selected.query('label_binary == 1').sample(n = 1)\n",
    "\n",
    "    print('label: ', sample_pos.label_binary.values[0])\n",
    "\n",
    "    print(sample_pos['text'].values[0][:200])\n",
    "\n",
    "    print('label: ', sample_neg.label_binary.values[0])\n",
    "\n",
    "    print(sample_neg['text'].values[0][:200])\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лемматизация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#уберем все лишние символы кроме букв, приведем к нижнему регистру\n",
    "def clear_text(text):\n",
    "    clear_text = re.sub(r'[^А-яЁё]+', ' ', text).lower()\n",
    "    return \" \".join(clear_text.split())\n",
    "\n",
    "\n",
    "#удалим стоп-слова\n",
    "def clean_stop_words(text, stopwords):\n",
    "    text = [word for word in text.split() if word not in stopwords]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'на', 'когда', 'ним', 'в', 'один', 'иногда', 'себе', 'этого', 'то', 'через', 'к', 'два', 'вас', 'этот', 'наконец', 'ничего', 'все', 'да', 'там', 'более', 'раз', 'перед', 'были', 'быть', 'про', 'потому', 'хоть', 'совсем', 'что', 'надо', 'тебя', 'если', 'ж', 'бы', 'еще', 'даже', 'они', 'ему', 'тот', 'тогда', 'как', 'у', 'меня', 'до', 'чтобы', 'всего', 'для', 'был', 'тоже', 'моя', 'будет', 'мой', 'потом', 'мы', 'другой', 'ли', 'него', 'была', 'всех', 'нее', 'можно', 'вдруг', 'между', 'я', 'с', 'такой', 'его', 'она', 'какая', 'же', 'за', 'он', 'при', 'разве', 'опять', 'мне', 'нет', 'о', 'где', 'или', 'без', 'по', 'ни', 'их', 'тут', 'ней', 'эти', 'всю', 'во', 'свою', 'будто', 'может', 'над', 'но', 'этой', 'чем', 'впрочем', 'нибудь', 'от', 'кто', 'из', 'них', 'чего', 'здесь', 'нас', 'вам', 'себя', 'тем', 'лучше', 'сейчас', 'им', 'после', 'а', 'много', 'хорошо', 'есть', 'куда', 'чтоб', 'так', 'под', 'нельзя', 'три', 'ведь', 'теперь', 'больше', 'со', 'уже', 'эту', 'том', 'сам', 'зачем', 'этом', 'никогда', 'уж', 'об', 'вы', 'и', 'вот', 'ну', 'только', 'ей', 'не', 'всегда', 'конечно', 'какой', 'почти', 'ты', 'ее', 'чуть', 'было', 'того'},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим список стоп-слов\n",
    "stopwords = set(nltk_stopwords.words('russian'))\n",
    "np.array(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка текстов заняла: 0.97 секунд\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abina Kukanova\\AppData\\Local\\Temp\\ipykernel_34376\\1966760752.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected['text_clear'] = selected['text'].apply(lambda x:clean_stop_words(clear_text(str(x)),stopwords))\n"
     ]
    }
   ],
   "source": [
    "start_clean = time.time()\n",
    "\n",
    "selected['text_clear'] = selected['text'].apply(lambda x:clean_stop_words(clear_text(str(x)),stopwords))\n",
    "\n",
    "print('Обработка текстов заняла: '+str(round(time.time() - start_clean, 2))+' секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df : (pd.Series, pd.DataFrame),\n",
    "              text_column : (None, str),\n",
    "              n_samples : int,\n",
    "              break_str = 'br',\n",
    "             ) -> pd.Series:\n",
    "\n",
    "\n",
    "    result = []\n",
    "\n",
    "    m = Mystem()\n",
    "\n",
    "    for i in tqdm(range((df.shape[0] // n_samples) + 1)) :\n",
    "\n",
    "        start = i * n_samples\n",
    "\n",
    "        stop = start + n_samples\n",
    "\n",
    "        sample = break_str.join(df[text_column][start : stop].values)\n",
    "\n",
    "        lemmas = m.lemmatize(sample)\n",
    "\n",
    "        lemm_sample = ''.join(lemmas).split(break_str)\n",
    "\n",
    "        result += lemm_sample\n",
    "\n",
    "    return pd.Series(result, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:59<00:00,  1.08it/s]\n",
      "C:\\Users\\Abina Kukanova\\AppData\\Local\\Temp\\ipykernel_34376\\959808114.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected['lemm_clean_tex'] = lemmatize(\n"
     ]
    }
   ],
   "source": [
    "selected['lemm_clean_tex'] = lemmatize(\n",
    "    df = selected,\n",
    "    text_column = 'text_clear',\n",
    "    n_samples = 100,\n",
    "    break_str = 'br',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>text_clear</th>\n",
       "      <th>lemm_clean_tex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Но при мужчине ни одна приличная женщина не по...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>мужчине одна приличная женщина пойдет лазить р...</td>\n",
       "      <td>мужчина один приличный женщина пойти лазить ра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Украина это часть Руси искусственно отделенная...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>украина это часть руси искусственно отделенная...</td>\n",
       "      <td>украина это часть русь искусственно отделять к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как можно говорить об относительно небольшой к...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>говорить относительно небольшой коррупции обра...</td>\n",
       "      <td>говорить относительно небольшой коррупция обра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Государство не может сейчас платить больше и м...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>государство платить посмотрите денежный поток ...</td>\n",
       "      <td>государство платить посмотреть денежный поток ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>эксплуатируемые способны только на бунты - бес...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>эксплуатируемые способны бунты бессмысленные б...</td>\n",
       "      <td>эксплуатируемые способный бунт бессмысленный б...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  label_binary  \\\n",
       "0  Но при мужчине ни одна приличная женщина не по...   -1.0           0.0   \n",
       "1  Украина это часть Руси искусственно отделенная...   -1.0           0.0   \n",
       "2  Как можно говорить об относительно небольшой к...   -1.0           0.0   \n",
       "5  Государство не может сейчас платить больше и м...   -1.0           0.0   \n",
       "8  эксплуатируемые способны только на бунты - бес...   -1.0           0.0   \n",
       "\n",
       "                                          text_clear  \\\n",
       "0  мужчине одна приличная женщина пойдет лазить р...   \n",
       "1  украина это часть руси искусственно отделенная...   \n",
       "2  говорить относительно небольшой коррупции обра...   \n",
       "5  государство платить посмотрите денежный поток ...   \n",
       "8  эксплуатируемые способны бунты бессмысленные б...   \n",
       "\n",
       "                                      lemm_clean_tex  \n",
       "0  мужчина один приличный женщина пойти лазить ра...  \n",
       "1  украина это часть русь искусственно отделять к...  \n",
       "2  говорить относительно небольшой коррупция обра...  \n",
       "5  государство платить посмотреть денежный поток ...  \n",
       "8  эксплуатируемые способный бунт бессмысленный б...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        мужчина один приличный женщина пойти лазить ра...\n",
       "1        украина это часть русь искусственно отделять к...\n",
       "2        говорить относительно небольшой коррупция обра...\n",
       "5        государство платить посмотреть денежный поток ...\n",
       "8        эксплуатируемые способный бунт бессмысленный б...\n",
       "                               ...                        \n",
       "26864    великое испытание выпадать доля наш предок веч...\n",
       "26865    н свой поведение крайне низкий человек прощать...\n",
       "26866    многие психологический книга кричать женщина д...\n",
       "26868    многих заставлять многий сам проявлять излишни...\n",
       "26869    очередной чубайс новый сорос х давать исчерпыв...\n",
       "Name: lemm_clean_tex, Length: 12938, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected['lemm_clean_tex']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим на положительные и отрицательные\n",
    "positive_df = selected[selected['label_binary'] == 1.0]\n",
    "negative_df = selected[selected['label_binary'] == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tokens = []\n",
    "for line in positive_df['lemm_clean_tex']:\n",
    "    positive_tokens.append(word_tokenize(line))\n",
    "\n",
    "negative_tokens = []\n",
    "for line in negative_df['lemm_clean_tex']:\n",
    "    negative_tokens.append(word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "positive_tokens = reduce(operator.concat, positive_tokens)\n",
    "negative_tokens = reduce(operator.concat, negative_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Возвращает словарь {слово: абсолютная частота встречаемости} на основе списка слов positive_tokens\n",
    "pos_freq = {}\n",
    "for pos_word in positive_tokens:\n",
    "    if pos_word in pos_freq:\n",
    "        pos_freq[pos_word] += 1\n",
    "    else:\n",
    "        pos_freq[pos_word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Возвращает словарь {слово: абсолютная частота встречаемости} на основе списка слов negative_tokens\n",
    "neg_freq = {}\n",
    "for neg_word in negative_tokens:\n",
    "    if neg_word in neg_freq:\n",
    "        neg_freq[neg_word] += 1\n",
    "    else:\n",
    "        neg_freq[neg_word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выбросим слова, которые встречаются только 1-2 раза\n",
    "pos_words = []\n",
    "for pos_word, freq_word in pos_freq.items():\n",
    "    if freq_word > 2:\n",
    "        pos_words.append(pos_word)\n",
    "\n",
    "neg_words = []\n",
    "for neg_word, freq_word in neg_freq.items():\n",
    "    if freq_word > 2:\n",
    "        neg_words.append(neg_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть два множества: положительные pos_set и негативные neg_set. Разница между pos_set и neg_set (pos_set — neg_set) — это множество со всеми элементами, которые содержатся в pos_set, но не в neg_set. Соответственно, (neg_set — pos_set) — это множество со всеми элементами в neg_set, но не в pos_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_pos = pos_set.difference(neg_set)\n",
    "diff_neg = neg_set.difference(pos_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках этого задания мы будем создавать программу, которая получая на вход отзыв, будет предсказывать, является отзыв положительным или отрицательным. Делать мы будем это таким образом: мы возьмём некоторое число отзывов, заранее размеченных как положительные или отрицательные; выделим те слова, которые встречаются только в положительных или только в отрицательных отзывах, и будем считать, каких слов в поступившем нам на проверку отзыве больше.\n",
    "\n",
    "Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy (1 - за коректно работающую функцию, 1 - за подсчёт accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "def sentiment_analysis(reply):\n",
    "    clear_text = re.sub(r'[^А-яЁё]+', ' ', text).lower()\n",
    "    lemmas = m.lemmatize(clear_text)\n",
    "    lemm_text = ''.join(lemmas)\n",
    "    tokens = word_tokenize(lemm_text)\n",
    "    sample_set = set(tokens)\n",
    "    if sample_set.intersection(diff_pos) > sample_set.intersection(diff_neg):\n",
    "        print('positive')\n",
    "    else:\n",
    "        print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "#В нашем датасете этот комментарий был негативным, и наша функция вывела, что этот комментарий тоже негативный\n",
    "text = \"\"\"html  Еще пара таких инициатив и я тоже буду голосовать за Мерец.\n",
    "  Ну чо, 20 лет прошло поколение сменилось , можно опять, как в 92 -м ,\n",
    "    сделать кучу мандатов на борьбе с религиозным засильем и за соц\"\"\"\n",
    "b = sentiment_analysis(text)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вытащим первые пять положительных и отрицательных комментариев, чтобы проверить функцию и рассчитать accuracy\n",
    "scrapped = {}\n",
    "for line in positive_df['text'].head():\n",
    "    scrapped[line] = \"positive\"\n",
    "\n",
    "for line in negative_df['text'].head():\n",
    "    scrapped[line] = \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(scrapped.values())\n",
    "scrapped_keys = list(scrapped.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "b = []\n",
    "def sentiment(reply):\n",
    "    clear_text = re.sub(r'[^А-яЁё]+', ' ', text).lower()\n",
    "    lemmas = m.lemmatize(clear_text)\n",
    "    lemm_text = ''.join(lemmas)\n",
    "    tokens = word_tokenize(lemm_text)\n",
    "    sample_set = set(tokens)\n",
    "    if sample_set.intersection(diff_pos) > sample_set.intersection(diff_neg):\n",
    "        b.append('positive')\n",
    "    else:\n",
    "        b.append('negative')\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in scrapped_keys:\n",
    "    y_pred = sentiment(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "r = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "r = numpy.flip(r)\n",
    "\n",
    "acc = (r[0][0] + r[-1][-1]) / numpy.sum(r)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход нашей функции мы подали 10 комментариев, первые пять из которых были положительными, а другие отрицательными, но наша функция вывела, что все комментарии отрицательные. На основе матрицы ошибок рассчитали accuracy и получили 0,5. Вы можете видеть, что точность довольно низкая – всего 50%, что довольно разочаровывает при всей этой работе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предложите как минимум 2 способа улучшить этот алгоритм определения тональности отзыва (1 балл за описание и реализацию каждого способа; если 2 способа описаны только текстом, это 1 балл. За третий и последующие способы дополнительных баллов не будет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первый способ\n",
    "\n",
    "Мы возьмем только существительные, глаголы, прилагательные и наречия из наших комментариев. Мы будем использовать SentiWordNet для вычисления полярности. Тональностью будет разница между положительным и отрицательным результатом. Возьмем список синонимов и и первый синоним в этом списке для вычисления отношения . Тональность каждого комментария будет средним значением каждого слова. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = selected.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на обучающую и тестовую выборки \n",
    "train_X, test_X, train_y, test_y = train_test_split(selected['text'], selected['label_binary'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Abina Kukanova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\Abina\n",
      "[nltk_data]     Kukanova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def sentiment_sentiwordnet(text):\n",
    "    clear_text = re.sub(r'[^А-яЁё]+', ' ', str(text)).lower()\n",
    "    raw_sentences = sent_tokenize(clear_text)\n",
    "    sentiment = 0\n",
    "    tokens_count = 0\n",
    "\n",
    "    for raw_sentence in raw_sentences:\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "\n",
    "        for word, tag in tagged_sentence:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "\n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            word_sent = swn_synset.pos_score() - swn_synset.neg_score()\n",
    "\n",
    "            if word_sent != 0:\n",
    "                sentiment += word_sent\n",
    "                tokens_count += 1\n",
    "\n",
    "    if tokens_count == 0:\n",
    "        return 0\n",
    "    sentiment = sentiment/tokens_count\n",
    "    if sentiment >= 0.01:\n",
    "        return 1\n",
    "    if sentiment <= -0.01:\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8483908491663436"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred_y = [sentiment_sentiwordnet(text) for text in test_X]\n",
    "accuracy_score(test_y.to_list(), pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что accuracy значительно увеличилась - 0.8483908491663436. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Второй способ \n",
    "\n",
    "Используем модель логистической регрессии, чтобы предсказать положительные и отрицательные отзывы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(selected['text'], selected['label_binary'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words(\"russian\")\n",
    "tfidf = TfidfVectorizer(stop_words=stops, binary=True, max_features=10000)\n",
    "tfidf.fit(train_X)\n",
    "X_train = tfidf.transform(train_X)\n",
    "X_test = tfidf.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.879798371461807"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, train_y)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовав  модель логистической регрессии, мы получили accuracy больше, чем в нашем первом алгоритме и в первом способе - 0.879798371461807. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
